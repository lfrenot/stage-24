\documentclass[11pt]{article}

\usepackage[style=numeric, natbib]{biblatex}
\usepackage[margin=20ex]{geometry}
\usepackage{amsmath}
\usepackage{array}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{fancyvrb}
\usepackage{graphicx}
\usepackage{hypdoc}
\usepackage{libertine}
\usepackage{longtable}
\usepackage{newtxmath}
\usepackage{tabularx}
\usepackage{zi4}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{microtype}
\usepackage{balance}
\usepackage{mathtools}
\usepackage{float}
\usepackage{color}
\usepackage{listings,lstlangcoq}
\usepackage[dvipsnames]{xcolor}
\usepackage[all]{xy}
\usepackage{xspace}

\lstdefinestyle{customcoq}{
  columns=flexible,
  mathescape=true,
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  xleftmargin=\parindent,
  language=Coq,
  morekeywords={Variant, fun, Arguments, Type, cofix},
  % morekeywords={SOCKAPI,ITREE,data_at,data_at_},
  emph={%
    SOCKAPI,ITree,data_at,data_at_
  },
  emphstyle={\bfseries\color{green!40!red!80}},
  showstringspaces=false,
  basicstyle=\small\ttfamily,
  keywordstyle=\bfseries\color{green!20!black},
  commentstyle=\itshape\color{red!40!black},
  identifierstyle=\color{violet!50!black},
  stringstyle=\color{orange},
  escapeinside={<@}{@>}
}
\newcommand{\inlinecoq}[1]{\mbox{\lstinline[style=customcoq,columns=fixed,basewidth=.48em]{#1}}}
\newcommand{\ilc}[1]{\inlinecoq{#1}}

\addbibresource{references.bib}

\newcommand{\leon}[1]{\textcolor{blue}{#1}}
\newcommand{\yz}[1]{\textcolor{ForestGreen}{#1}}
\newcommand{\yzt}[1]{\textcolor{ForestGreen!50}{#1}}
\newcommand{\cut}[1]{\textcolor{Gray!40}{#1}}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

\newcommand{\ocfg}{OCFG\xspace}
\newcommand{\pat}{\texttt{Pat}\xspace}

\hypersetup{colorlinks=true, linkcolor=black}

\begin{document}

\title{CFG Patterns: A new tool to formally verify optimisations in Vellvm}

\author{Leon Frenot\\ Supervised by Yannick Zakowski \& Gabriel Radanne}

\date{February 5th, 2024 - July 5th, 2024}

\begin{titlepage}
  \centering
  {\textsc{École normale supérieure de Lyon} \par}
  \vspace{1cm}
  {\Large \textsc{Internship Report}\par}
  \vspace{1.5cm}
  {\huge\bfseries CFG Patterns: A new tool to formally verify optimisations in Vellvm\par}
  \vspace{2cm}
  {\Large\itshape Leon Frenot\par}
  \vfill
  supervised by\par
  Yannick~Zakowski~\&~Gabriel~Radanne\par
  at ENS Lyon
  \vfill

  % Bottom of the page
  {\large February 5th, 2024 - July 5th, 2024\par}
\end{titlepage}

\tableofcontents
\newpage

\hypersetup{colorlinks=true, linkcolor=red}

\begin{abstract}
  \leon{Abstract}
\end{abstract}

\section{Introduction}
\label{sec:intro}

\indent
For my M2 year at ENS de Lyon, I completed a 20 weeks internship in the LIP Computer Science laboratory in ENS Lyon. This internship was supervised by Yannick Zakowski and Gabriel Radanne in the Compilation and Analysis, Software and Hardware Laboratory of the LIP. The goal of this internship was to design and implement a pattern language over control flow graphs to provide a framework for formal proofs on optimizations.

\leon{Compilation certifiée AJD}

\paragraph{}
\leon{Importance de la compilation certifiée, et surtout de certifier les optims.}

\paragraph{The Contribution of This Work}

\begin{itemize}
  \item \leon{Design d'un langage de patterns + Implémentation naive d'un matcher}
  \item \leon{Preuve d'un théorème central pour prouver des optims (sur un CFG)}
  \item \leon{Utiliser ce langage pour block fusion + preuve de correction}
\end{itemize}
\paragraph{Premier exemple: CCstP}

\section{Background}
\label{sec:background}

\subsection{Interaction Trees}

Interaction Trees (ITrees) are a co-inductive structure designed to represent the dynamic behaviors of a computation. The goal of ITrees is to model recursive and effectful programs, including divergent computations.\\
Figure~\ref{fig:itree} show the Coq definition of ITrees. An instance of the type features an \emph{event} type \ilc{E: Type -> Type}, and a return type \ilc{R: Type}. The definition uses three constructors: \ilc{Ret} corresponds to halting and returning a value of type \ilc{R}; \ilc{Tau} corresponds to a \emph{silent step}, i.e. an internal computation, followed by computation \ilc{t}; and \ilc{Vis} which is a \emph{visible event}, it describes an external computation \ilc{e} which returns a value of type \ilc{A}, and a continuation \ilc{k} which depends on that return value.

\begin{figure}[h]
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
CoInductive itree (E : Type -> Type) (R : Type) : Type :=
  | Ret (r : R)
  | Tau (t : itree E R)
  | Vis {A : Type} (e : E A) (k : A -> itree E R).
  \end{lstlisting}
  \caption{The \ilc{itree} datatype}
  \label{fig:itree}
\end{figure}

To reason over ITrees, we have multiple notions of \emph{bisimulation}. The most relevant one is \emph{weak bisimulation}, noted \ilc{t1 ≈ t2}. We say that \ilc{t1 ≈ t2} if they return the same value, and have the same visible events. This relation is an equivalence ``up-to-Tau'' in the sense that we have \ilc{Tau t ≈ t} and \ilc{t ≈ Tau t}. This equivalence be refined up to a relationship $R : A \rightarrow B \rightarrow Prop$: we then have $\ilc{Ret}\; a \approx_R \ilc{Ret}\; b \iff R\; a\; b$. 

Effects can easily be added or removed from the semantics of an ITree. The \ilc{Vis} constructor represents \emph{uninterpreted events}. By defining an \emph{event handler}, semantics are assigned to these events. Interpreting an ITree then consists of folding that handler over the ITree. This allows the semantics of ITrees to be \emph{modular}.

Furthermore, the semantics of ITrees are also \emph{compositional} with the use of \emph{combinators}. For example, \ilc{bind: itree E A -> (A -> itree E B) -> itree E B} allows composing ITrees (with the use of continuations).
Other combinators include \ilc{iter: (A -> itree E (A+B)) -> (A -> itree E B)} to encode the iterations and hide the co-induction (by hiding each body step in a Tau), and \ilc{mrec} for mutual-recursive combinators. 

Unlike similar projects, which rely on \emph{operational semantics} and simulation diagrams, ITrees rely on \emph{denotational semantics}. That is, it is based on equations that can be used to prove bisimulation. These equations allow the user to reason equationally, hiding the co-inductive reasoning and the definition of the weak bisimulation. The compositionality of the semantics also allow simpler reasoning than operational semantics, since program counter and similar notions are lifted away.

\subsection{Vellvm}

\leon{TODO: figures (vir syntax and intrep stack), emphs}

The goal of the Vellvm project is to formally define the semantic of the LLVM IR and construct verified
components for that formalization.

LLVM is a compiler infrastructure designed around a language-independent intermediate representation (IR). It is used to develop frontends for programming languages and backends for instruction set architectures.\\
The LLVM IR is a RISC-like low level instruction set, but also features high-level informations. This duality allows it to represent any program while still permuting analysis and optimizations. It is based on control flow-graphs, with named labels and registers, and guarantees Single Static Assignment (SSA) form, which is key to many static analyses and optimizations. The LLVM IR is statically typed, and features integer-pointer casts.
Optimizations ans analysis on the LLVM IR are done through successive analysis and transformation passes.

Vellvm introduces Verified LLVM IR (VIR), a realistic subset of the LLVM IR. Figure~\ref{vir} shows a subset of VIR's syntax. VIR's semantics are defined with ITrees: each element of VIR's syntax is represented by a corresponding ITree. Each effect (except control flow) is captured by a \ilc{Vis} event, which can be interpreted later. This semantic includes many non-trivial features of LLVM IR, including pointers, LLVM's phi-nodes and undefined behaviors.

Since the semantics of a block or set of blocks can be defined without relying on a ``complete'' CFG, it is possible to use ``open control-flow graphs'' (\ocfg), which is simply a set of blocks without a defined entry point.

Finally, to interpret the semantics of the different effects of its syntax, Vellvm uses a stack of interpreters. It allows to gradually introduce external elements to the semantic (intrinsics, global and local environments, \ldots). Figure~\ref{interp} show that stack of interpretation. The final levels split between a \emph{propositional} model, which interprets the non-determinism of LLVM IR's undefined behaviors, and a \emph{executable} model, which implements one of these behaviors.

\section{The pattern language}
\label{sec:lang}

\yz{De façon générale, commencer par des bullet points ou des séries de paragraphe est excellent, mais c'est important de lui donner corps en rédigeant dans un second temps un texte cohésif. Je tente une proposition rapide par exemple pour ce chapeau pour illustrer.}

\yz{Remarque générale : il faut utiliser beaucoup beaucoup de macros quand on écrit du TeX. Par exemple OCFG va apparaître beaucoup, et on peut hésiter sur la façon de le typeset/écrire : macro }

\yz{Il peut être pratique d'avoir un nom pour ton langage pour pouvoir y référer.}

\yzt{We now turn our attention to the central piece of our contribution: the design of \pat{}, a DSL of patterns for writing and proving correct program transformations. This DSL is composed of two core components. First, an indexed datatype provides a syntax for the user to specify how they wish to decompose an input \ocfg. Second, a \emph{matcher} provides a semantics to the language, specifying the valid decompositions associated to each pattern. Finally, we illustrate on an example the definition and semantic characterization of a pattern extracting the heads of a graph, written in our DSL.}

\cut{
In this section we will:\begin{itemize}
  \item Define a Domain Specific Language that can capture optimizable subgraphs in an \ocfg\@.
  \item Introduce a matcher on this language and the corresponding semantics of each constructor.
  \item Present the Coq implementation of the language, matcher and semantics.
\end{itemize}
}

\subsection{\pat: a DSL for pattern matching on graphs}

\yzt{At a high level, we look for a language allowing the user to characterize and reason about optimizable subgraphs in an \ocfg. 
To this end, we introduce \pat, a general, very expressive DSL for pattern matching on graphs. The specific patterns we are interested in from the perspective of compilation will then be expressed in \pat.}

\begin{figure}[h]
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
    Inductive Pattern : Type -> Type :=
    | Graph: Pattern ocfg
    | When: forall  {S}, Pattern S -> (S -> bool) -> Pattern S
    | Map: forall  {S} {T}, Pattern S -> (S -> T) -> Pattern T
    | Focus: forall  {S}, Pattern S -> Pattern (ocfg * S)
    | Block: forall  {S}, Pattern S -> Pattern (bid * blk * S)
    | Head: forall  {S}, Pattern S -> Pattern (bid * blk * S)
    | Branch: forall  {S}, Pattern S -> Pattern (bid * blk * S)
  \end{lstlisting}
  \label{fig:pat}
  \caption{The \ilc{Pattern} datatype}
\end{figure}

\yz{Attention il faut TOUJOURS, équipper les objets flottants d'un label, ET y faire référence dans le texte. Tu as fait le premier, mais pas le second ici :)}

\yz{Attention, l'idée d'un tel type indexé n'est pas évident pour beaucoup de lecteurs. Il est bon de prendre ton temps pour l'introduire.}

Figure~\ref{fig:pat} introduces \pat{}'s syntax, defined as an inductive datatype \ilc{Pattern}.
Because the purpose of a pattern is to decompose a graph into a certain structure, the \ilc{Pattern} datatype reflects this intention by taking as argument a type, which represents the return type of the pattern.\footnote{Such families of types are common in dependently typed languages, and are referred to as Generalized Algebraic Data Types in languages such as OCaml or Haskell.}
This typing information is leveraged in the definition of the matcher, introduced in Section~\ref{sec:matcher}: a pattern of type \ilc{Pattern S} will be matched against elements of type \ilc{S}.

\yz{Attention ici il est beaucoup plus digeste et élégant d'éviter une telle succession de paragraphes, et plutôt construire du texte. Je commence pour illustrer ce que j'imagine.}

\yzt{Patterns are built out of seven constructors. The only base case is the \ilc{Graph} pattern which trivially match any graph and does not perform any decomposition. On more traditional paper presentation, it corresponds to a single hole $\square$.}

\yzt{The six other constructors recursively decompose the graph, typically enriching the return type of the pattern in doing so. 
The \ilc{When} constructor acts as a filter:
given a pattern of return type \ilc{S}, it builds a pattern with the same return type, but takes as argument a filtering function \ilc{S -> bool} used to restrict the set of matching graphs to those satisfying the condition.
The \ilc{Map} constructor simply hardcodes functoriality into the datatype, allowing for post-processing the output of a pattern by a pure function.
}

\yz{TODO: finir d'intégrer les paragraphes ci-après dans le texte ci-dessus.}


Each constructor adds to the return types of the following constructors, with the base case \ilc{Graph} accepting any graph.

We will now introduce each constructor and their function.

\paragraph{\ilc{Graph}}

The \ilc{Graph} constructor is the ``base'' case that matches any graph. It does not take any extra argument, and returns the graph given as argument.

\paragraph{\ilc{When}}

The \ilc{When} constructor allows adding a boolean condition to a pattern.
It takes a pattern and a corresponding boolean function as argument, and returns what the patterns matched if it fulfils the condition.

\paragraph{\ilc{Map}}

The \ilc{Map} constructor allows mapping a function onto a pattern's return type.
It takes a pattern and a function as argument, and returns the image of the function by what the patterns matched.

\paragraph{\ilc{Focus}}

The \ilc{Focus} constructor matches any subgraph.
It takes a pattern as argument to match against the rest of the graph, and returns the matched subgraph and what the pattern matched.

\paragraph{\ilc{Block}}

The \ilc{Block} constructor matches any single block in the graph.
It takes a pattern as argument to match against the rest of the graph, and returns the matched block and what the pattern matched.

\paragraph{\ilc{Head}}

The \ilc{Head} constructor matches any block of the graph without predecessors.
It takes a pattern as argument to match against the rest of the graph, and returns the matched block and what the pattern matched.\\
Note that this constructor could not be directly implemented as a \ilc{When (Block \_) \_} since it depends on the rest of the graph, which \ilc{When} wouldn't have access to.
\yz{TODO: expand on this note, detailing what filter you would want to write and pointing out why you can't precisely.
In particular, explain that you could write \ilc{When (Block Graph) (fun '(i,bk,g) => is_head i g)}, but not \ilc{fun p => When (Block p) (fun s => ???)}, and why it may matter.}

\paragraph{\ilc{Branch}}

The \ilc{Branch} constructor matches any block of the graph whose terminator is a conditional jump.
It takes a pattern as argument to match against the rest of the graph, and returns the matched block and what the pattern matched.
This constructor could be implemented as a \ilc{When (Block \_) \_}, but has been implemented directly because \leon{???}.\yz{Give the exact definition in terms of when/block, and indeed justify.}

\yz{Je pense qu'il faut insérer ici une discussion assez généreuse sur le choix de ce jeu de constructeurs : remarquer qu'il y a de la redondance, en pointant du doigt que tout pattern fixé peut être encodé avec Focus, Graph et When (à vérifier que c'est vrai) par exemple, mais pas des familles de patterns qui composent; remarquer que Map parait assez naturel, mais que l'on en a pas d'usage en ce moment; expliquer que l'on cherche un point de design alliant facilité d'utilisation et facilité de développer la méta-théorie, et que ce n'est pas encore fixé dans le marbre.}

\paragraph*{An example of pattern: block fusion.}
We illustrate the use of \pat{} to implement\footnote{Or rather, to \emph{specify} such an optimization. We discuss briefly executability in conclusion.} a bloc fusion optimization. 
That is: fusing two blocks whose execution always follow each other into a single block. \yz{Explain the optimisation in a little bit more details (unless you plan on introducing it in more detail earlier in the paper, in which case put a reference to it).}

\yz{Note: it's almost never a good idea to force a return carriage via a double slash.}

The applicable subgraphs are specified with the pattern \ilc{When (Block (Head Graph)) BlockFusion\_f}. \yz{Name the pattern, like \ilc{pfusion} for instance, you will want to refer to it later to give its spec.}
The pattern starts by the \ilc{Block} to match any block \ilc{bk} \yz{(What does first mean here? I think you just mean to say that's the first thing you match on. I would rather give a name to this block, and not refer to it by the name of the pattern!)}. Then, \ilc{Head} matches a block \ilc{head} that has no predecessors (except possibly \ilc{bk} as it is not in scope of the pattern anymore), and finally \ilc{When _ BlockFusion\_f} sets additional constraints on the two blocks required for the optimization to be valid.\yz{Give the code for BlockFusion\_f and explain these additional constraints in details.}

\begin{figure}[h]
  \xymatrix{
    &&&&\\
    &*+[F]\txt{Block\\Any block}\ar[dd]&&\;\ar@{-->}`u[ul] `[ll] [ll]&\\
    *+[F.]\txt{BlockFusion\_f\\Sets conditions on\\the two blocks}\ar@{..>}`u[ur] [ur]\ar@{..>}`d[dr] [dr]&&&\txt{Graph}\\
    &*+[F]\txt{Head\\No predecessors\\once Block is removed}\ar@{-->}`d[dr] `[rr] [rr]&&&\\ 
    &&&
    \save "2,3"."4,5"*[F--]\frm{} \restore
  }
  \caption{The \ilc{BlockFusion} pattern}
  \label{fig:fusion}
\end{figure}

\yz{Refer to and explain the figure! "Figure~2 illustrate graphically the shape of the graph decompositions that match \ilc{pfusion} ..." Use the names suggested above, and explain the meaning of the different arrows.}

\subsection{Matcher functions}
\label{sec:matcher}

We now turn to the question of defining the semantics of our patterns, via a \emph{matcher function}. 
\yzt{Such function takes a pattern \ilc{p} and an \ocfg{} \ilc{G} as arguments, and returns a set of decompositions of \ilc{G} that match \ilc{p}.}
\yzt{We have mainly focused so far on \emph{specifying} patterns, by implementing a matcher that returns \emph{all} valid decompositions. 
Although rather meant as a specification than as a realistic implementation, the \ilc{MatchAll} function, depicted in Figure~\ref{fig:matchall}, is nonetheless executable. This not only allows for testing, but also drastically the distance left to bridge to reach a provably sound, efficient implementation. To do so, the matcher lives in the list monad: it computes recursively the decomposition according to the sub-pattern, and flat maps (Definition provided on Figure~\ref{fig:flatmap}) a function for each constructor extending the decomposition according to the head constructor.}

\begin{figure}[H]
  \label{fig:match}
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
    Fixpoint MatchAll {S} (P: Pattern S) (g: ocfg) : list S :=
    match P with
      | Graph => [g]
      | When p f => filter (fun x => f x = true) (MatchAll p g) 
      | Map p f => map f (MatchAll p g)
      | Focus p => flat_map_r (MatchAll p) (focus g)
      | Block p => flat_map_r (MatchAll p) (blocks g)
      | Head p => flat_map_r (MatchAll p) (heads g)
      | Branch p => flat_map_r (MatchAll p) (branches g)
    end.
  \end{lstlisting}
  \caption{The \ilc{MatchAll} function}
  \label{fig:matchall}
\end{figure}

\begin{figure}[h]
  \label{fig:fmapr}
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
    Definition flat_map_r {A B C} (f : B -> list C) :=
      fix flat_map_r (l : list (A*B)) : list (A*C) :=
        match l with
        | [] => []
        | (a, b)::q => (map (fun c => (a, c)) (f b))++flat_map_r q
    end.
  \end{lstlisting}
  \caption{The \ilc{flat_map_r} function \yz{Use Fixpoint in this code, nesting a fix is superficial and confusing for non coq experts}}
  \label{fig:flatmap}
\end{figure}

\yz{Where are the descriptions of focus / block / heads / branches ??? To insert here}
\yz{Ah je vois que tu mets celle de head ci-dessous. Il faut bien découpler la descsription de MatchAll de la specification du langage et la preuve de correction de matchall. Et à moins que tu manques de place, je donnerais les défs des quatres.}

\paragraph*{Specification.}
\yzt{We have claimed that \ilc{MatchAll} \emph{returns all valid decompositions}. We capture this statement by providing specifications for each constructor of \pat, and proving they are exactly captures by \ilc{MatchAll}.}

Proving the correctness for \ilc{Graph}, \ilc{When} and \ilc{Map} is immediate thanks to builtin lemmas on \ilc{filter} and \ilc{map}. \yz{Tu n'as pas énoncé cette correction, on ne peut donc comprendre en quoi c'est immédiat !}

The proof mechanism for \ilc{Block}, \ilc{Head} and \ilc{Branch} are similar. We will now detail it for \ilc{Head}.\yz{Comme dit au dessus, pousser la partie définition de heads au dessus, et garder la partie spec et preuve ici.}

\ilc{MatchAll} relies on the \ilc{heads} function to match the \ilc{Head} constructor.\\
The goal of that function is to find all the "heads", i.e. blocks without predecessors, in an OCFG.\\
To do that, it folds a \ilc{heads_aux} function over the map. That function calls the \ilc{predecessors} function on each block, and appends the result to the return list if the block doesn't have predecessors.

\begin{figure}[H]
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
    Definition heads_aux (G: ocfg) id b acc : list (bid*blk*ocfg) :=
      if is_empty (predecessors id G)
      then (id, b, delete id G)::acc
      else acc.

    Definition heads (G: ocfg): list (bid*blk*ocfg) := map_fold (heads_aux G) [] G.
  \end{lstlisting}
  \caption{The \ilc{heads} function}
  \label{fig:heads_fun}
\end{figure}

With these function, we can define the semantics corresponding to each function. We have to define them first for the auxiliary function for the semantics proof.

\begin{figure}[H]
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
    Record heads_aux_sem (G0 G G': ocfg) id b := {
      EQ: G' = delete id G0;
      IN: G !! id = Some b;
      PRED: predecessors id G0 = ∅
    }.

    Definition heads_sem (G G':ocfg) (id:bid) b := heads_aux_sem G G G' id b.
  \end{lstlisting}
  \caption{The semantic definition for \ilc{Head/heads}}
  \label{fig:sem_block_def}
\end{figure}

Finally, we can prove the semantics for the auxiliary function, the \ilc{heads} function and \ilc{MatchAll Head}.

\begin{figure}[H]
  \label{fig:block_cor}
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
    Definition heads_aux_P G0 (s:list (bid*blk*ocfg)) G :=
      forall id b G', (id, b, G') ∈ s IFF heads_aux_sem G0 G G' id b.

    Lemma heads_aux_correct:
      forall G G0,
      heads_aux_P G0 (map_fold (heads_aux G0) [] G) G.

    Lemma heads_correct:
      forall G G' id b,
      (id, b, G') ∈ (heads G) IFF heads_sem G G' id b.

    Theorem Pattern_Head_correct {S}:
      forall (G: ocfg) (P: Pattern S) id b X,
      (id, b, X) ∈ (MatchAll (Head P) G) IFF
      exists G', heads_sem G G' id b /\ X ∈ (MatchAll P G').
  \end{lstlisting}
\end{figure}

\yz{Décrire en anglais tout cela.}

\section{Denotation}
\label{sec:deno}

In this section we will informally define an optimization class, show a theorem for proving the correctness of optimizations of that class, and apply this theorem to an implementation of Block Fusion.

\subsection{An optimization class}

Since the goal of the patterns is to identify subgraphs, we want to focus on optimizations that only modify a section of the graph. (As opposed to ones that may modify everything, like constant propagation.)\\
Ideally, we want to be able to replace any subgraph with an equivalent subgraph.

\begin{figure}[h]
  \xymatrix{
    &&&&&&&&\\
    G_2&\approx&G_2'&\implies&*+[F]{G_2}\ar@{-->}`d[dr] `[r] [r]&*+[F]{G}\ar@{-->}`u[ul] `[l] [l]&\approx&*+[F]{G_2'}\ar@{-->}`d[dr] `[r] [r]&*+[F]{G}\ar@{-->}`u[ul] `[l] [l]\\
    &&&&&&&&
  }
\end{figure}
\begin{figure}[h]
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
Theorem (g1 g2 g2' : ocfg):
  forall from to, ⟦g2⟧bs (from,to) ≈ ⟦g2'⟧bs (from, to) ->
  forall from to, ⟦g2 ∪ g1⟧bs (from,to) ≈ ⟦g2' ∪ g1⟧bs (from, to).
  \end{lstlisting}
\end{figure}

However, this ideal theorem is not enough. In the case of Block Fusion for example, since we replace two blocs by one, the change in ids means that either we have to enter by different ids, or we have to exit by different ids.\\
There needs to be some renaming. We chose to apply the renaming to \ilc{to} and to \ilc{g1}'s terminators, since that keeps the semantics equivalent.

We define a function \ilc{ocfg_term_rename} which, given a function over ids \ilc{SIG} and a graph \ilc{g}, returns \ilc{g} with \ilc{SIG} applied to each id in its blocks' terminators.\\
This new function gives us the following theorem:
\begin{figure}[h]
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
Theorem (g1 g2 g2' : ocfg) (σ : bid -> bid):
  forall from to, ⟦g2⟧bs (from,to) ≈ ⟦g2'⟧bs (from, SIG to) ->
  forall from to, ⟦g2 ∪ g1⟧bs (from,to) ≈ ⟦g2' ∪ ocfg_term_rename σ g1⟧bs (from, SIG to).
  \end{lstlisting}
\end{figure}

However, this still cannot be applied to Block Fusion. Indeed, if we try to start on the second block, the semantics are obliviously different.\\
Similar issues can come from having an incorrect origin block. So we have to introduce two sets of ids \ilc{nTO} and \ilc{nFROM} to set condition on the input and origin ids.\\
\begin{figure}[H]
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
Theorem (g1 g2 g2' : ocfg) (σ : bid -> bid) (nFROM nTO: gset bid):
  (forall from to, to ∉ nTO -> from ∉ nFROM -> ⟦g2⟧bs (from,to) ≈ ⟦g2'⟧bs (from, SIG to)) ->
  forall from to, to ∉ nTO -> from ∉ nFROM -> ⟦g2 ∪ g1⟧bs (from,to) ≈ ⟦g2' ∪ ocfg_term_rename σ g1⟧bs (from, SIG to).
  \end{lstlisting}
\end{figure}

Finally, we need some conditions to make sure that:\begin{itemize}
  \item the unions are well-formed,
  \item \ilc{nFROM} and \ilc{nTO} are preserved during the (coinductive) proof,
  \item \ilc{SIG} only changes ids from \ilc{g2} to \ilc{g2'}.
\end{itemize}

These conditions give us the following final theorem:
\begin{figure}[H]
\begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
Theorem denote_ocfg_equiv
  (g1 g2 g2' : ocfg) (σ : bid -> bid) (nFROM nTO: gset bid) :
    inputs g2 ∩ inputs g2' ## nFROM -> nFROM ⊆ inputs g2 ∪ inputs g2' ->
    inputs g2' ∖ inputs g2 ⊆ nTO -> nTO ⊆ inputs g2 ∪ inputs g2' -> nTO ## outputs g1 ->
    g1 ## g2 -> ocfg_term_rename σ g1 ## g2' ->
    (forall id, id ∈ inputs g2 -> (σ id) ∈ inputs g2') ->
    (forall id, id ∉ nFROM -> (σ id) = id) ->
    (forall from to, to ∉ nTO -> from ∉ nFROM -> ⟦g2⟧bs (from,to) ≈ ⟦g2'⟧bs (from, SIG to)) ->
    forall from to,
    to ∉ nTO -> from ∉ nFROM ->
    ⟦g2 ∪ g1⟧bs (from,to) ≈ ⟦g2' ∪ ocfg_term_rename σ g1⟧bs (from, σ to).
  \end{lstlisting}
  \caption{The \ilc{denote_ocfg_equiv} theorem}
\end{figure}

\subsection{Motivations for Block Fusion}

In this section, we will define the Block Fusion optimization, describe a corresponding OCFG pattern,
and outline the proof of correctness of the optimization using the pattern.

The Block Fusion optimization consists of picking two blocks $A$ and $B$,
such that $A$ is the only predecessor of $B$ and $B$ is the only successor of $A$,
and replacing them with a single block containing the code of $A$ and $B$.

This optimization is relevant for three main reasons:\begin{itemize}
  \item It is a commonly used optimization, for example to clear blocks created while building SSA form.
  \item It is an optimization that modifies the graph.
  \item It is simple to prove on paper that the optimization is correct.
\end{itemize}

In the previous section, we already gave a pattern for \ilc{BlockFusion}, we will use a slight variation, which allows further composing:\\\ilc{Definition BlockFusion {S} (P: Pattern S) := When (Block (Head P)) BlockFusion_f.}

% \subsection{The semantics of Block Fusion}

\ilc{BlockFusion_f} has two conditions:\begin{itemize}
  \item the terminator of the first block is an absolute jump to the second block,
  \item the second block does not have phi nodes.
\end{itemize}

The first condition is needed (instead of just checking the successors) because, if there is a conditional jump, evaluating the condition may lead to an error, and so to a difference in semantic after the fusion.\\
The second condition is needed because of the difference in evaluation between phi-nodes and assignment operations.

With this, we can create a \ilc{fusion} function for Block Fusion (\ilc{term_rename} applies \ilc{SIG} to each id in the terminator).

\begin{figure}[H]
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
Definition fusion (σ: bid -> bid) (idA : bid) (A B: blk): blk := {|
  blk_phis       := A.(blk_phis);
  blk_code       := A.(blk_code) ++ B.(blk_code);
  blk_term       := term_rename σ B.(blk_term);
  blk_comments   := fusion_comments A B
|}.
  \end{lstlisting}
  \caption{The \ilc{fusion} function}
\end{figure}

We also define \ilc{SIGfusion}, the renaming function for Block Fusion:

\begin{figure}[H]
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
Definition σfusion idA idB := fun (id: bid) => if decide (id=idA) then idB else id.
  \end{lstlisting}
\end{figure}

With these, we can prove first that \ilc{fusion} is correct, and then that the Block Fusion optimization is correct.

\begin{figure}[H]
  \begin{lstlisting}[style=customcoq,basicstyle=\small\ttfamily]
Theorem Denotation_BlockFusion_correct {S} G idA A idB B f to P (X:S):
  let σ := σfusion idA idB in
  let G0 := delete idB (delete idA G) in
  to <> idB ->
  f <> idA ->
  (idA, A, (idB, B, X)) ∈ (MatchAll (BlockFusion P) G) ->
  ⟦ G ⟧bs (f, to) ≈ ⟦ <[idB:=fusion σ idA A B]> (ocfg_term_rename σ G0) ⟧bs (f, σ to).
      \end{lstlisting}
\end{figure}

\section{A voir: Approfondissements}
\label{sec:appr}

\subsection{Loop pattern}

\xymatrix{
  \ar[d]&&&\ar[d]\\
  *+[F]\txt{A}\ar@/^/[d]& & & *+[F]\txt{B}\ar@/^/[d]\\
  *+[F]\txt{B}\ar@/^/[u] \ar@/_/[dr]\ar[d]& & \Rightarrow & *+[F]\txt{A}\ar@/^/[u] \ar@/_/[dr]\ar[d]\\
  &*+[F]\txt{*}\ar@/_/[ul]& & & *+[F]\txt{*}\ar@/_/[ul]
}

\xymatrix{
  \ar[dd]&&&\ar[d]\\
  &&&*+[F]\txt{*}\ar[d]\\
  *+[F]\txt{A}\ar@/_/[dr]\ar[d]&&\Rightarrow&*+[F]\txt{A}\ar@/_/[dr]\ar[d]\\
  &*+[F]\txt{*}\ar@/_/[ul]&&&*+[F]\txt{*}\ar@/_/[ul]
}

\xymatrix{
  \ar[dd]&&&\ar[d]\\
  &&&*+[F]\txt{A}\ar@/_/[r]\ar[d]&*+[F]\txt{1}\ar@/_/[l]\\
  *+[F]\txt{A}\ar@/_/[dr]\ar[d]&*+[F]\txt{2}\ar@/_/[l]&\Rightarrow&*+[F]\txt{A'}\ar@/_/[r]\ar[d]&*+[F]\txt{2}\ar@/_/[l]\\
  &*+[F]\txt{1}\ar@/_/[u]&&&
}

\xymatrix{
  \ar[dd]&&&\ar[d]\\
  &&&*+[F]\txt{1}\ar[d]\\
  *+[F]\txt{A}\ar@/_/[dr]\ar[dd]&*+[F]\txt{2}\ar@/_/[l]&\Rightarrow&*+[F]\txt{A}\ar@/_/[dr]\ar[d]&*+[F]\txt{1}\ar@/_/[l]\\
  &*+[F]\txt{1}\ar@/_/[u]&&*+[F]\txt{2}\ar[d]&*+[F]\txt{2}\ar@/_/[u]\\
  &&&&&
}

\subsection{Other interpretation levels}

\subsection{Optim efficace}

\section*{Conclusion}
\label{sec:ccl}

\end{document}